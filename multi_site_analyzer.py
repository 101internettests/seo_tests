#!/usr/bin/env python3
"""
–ú—É–ª—å—Ç–∏—Å–∞–π—Ç–æ–≤—ã–π SEO –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è –≤—Å–µ—Ö —Å–∞–π—Ç–æ–≤
"""

import os
import sys
import argparse
import logging
import json
import requests
import time
from datetime import datetime
from typing import List, Dict, Any
from bs4 import BeautifulSoup

from google_sheets_service_account import GoogleSheetsServiceAccount
from telegram_bot import TelegramBot

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –±—É–¥–µ—Ç –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ –≤ main()

logger = logging.getLogger(__name__)


class SEOParser:
    """–ü—Ä–æ—Å—Ç–æ–π SEO –ø–∞—Ä—Å–µ—Ä –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤"""
    
    def __init__(self, delay_between_requests: float = 2.0, config: Dict[str, Any] = None, sheets_manager=None):
        self.delay_between_requests = delay_between_requests
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        self.config = config
        self.sheets_manager = sheets_manager
    
    def analyze_page(self, url: str) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        
        Args:
            url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
        """
        result = {
            'url': url,
            'timestamp': datetime.now().isoformat(),
            'status': 'error',
            'error': None,
            'headings': {},
            'comparison': {}
        }
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            
            # –ü–∞—Ä—Å–∏–º HTML
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
            headings = self._analyze_headings(soup)
            
            result.update({
                'status': 'success',
                'status_code': response.status_code,
                'headings': headings,
                'comparison': self._compare_with_previous(url, headings)
            })
            
            # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            if self.delay_between_requests > 0:
                time.sleep(self.delay_between_requests)
                
        except Exception as e:
            result['error'] = str(e)
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {url}: {e}")
        
        return result

    def _analyze_headings(self, soup: BeautifulSoup) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤, title –∏ description –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ"""
        headings = {}

        # –ê–Ω–∞–ª–∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ H1-H6
        for i in range(1, 7):
            tag = f'h{i}'
            elements = soup.find_all(tag)

            total_count = len(elements)
            non_empty_count = len([el for el in elements if el.get_text(strip=True)])

            headings[f'{tag}_total'] = total_count
            headings[f'{tag}_non_empty'] = non_empty_count

        # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        headings['total_headings'] = sum(headings[f'h{i}_non_empty'] for i in range(1, 7))

        # –ü–æ–¥—Å—á–µ—Ç title —Ç–µ–≥–æ–≤ —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º (–∏—Å–∫–ª—é—á–∞—è —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ "error")
        title_tags = soup.find_all('title')
        title_count = 0
        for title in title_tags:
            title_text = title.get_text(strip=True)
            if title_text and 'error' not in title_text.lower():
                title_count += 1
        
        headings['title_count'] = title_count
        headings['title_result'] = f"Title with content: {title_count}"

        # –ü–æ–¥—Å—á–µ—Ç meta description —Ç–µ–≥–æ–≤ —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º (–∏—Å–∫–ª—é—á–∞—è —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ "error")
        meta_descriptions = soup.find_all('meta', attrs={'name': 'description'})
        description_count = 0
        for meta in meta_descriptions:
            content = meta.get('content', '').strip()
            if content and 'error' not in content.lower():
                description_count += 1
        
        headings['description_count'] = description_count
        headings['description_result'] = f"Description with content: {description_count}"

        return headings
    
    def _compare_with_previous(self, url: str, current_headings: Dict[str, int]) -> Dict[str, Any]:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∏–∑ Google Sheets"""
        if not self.config:
            return {
                'status': 'no_config',
                'changes': {},
                'errors': ['–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω–∞ –≤ –ø–∞—Ä—Å–µ—Ä']
            }
            
        try:
            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            settings = self.config['default_settings']
            spreadsheet_id = settings.get('spreadsheet_id')
            sheet_name = settings.get('sheet_name', '–õ–∏—Å—Ç1')
            
            if not spreadsheet_id:
                return {
                    'status': 'no_spreadsheet_id',
                    'changes': {},
                    'errors': ['–ù–µ —É–∫–∞–∑–∞–Ω ID —Ç–∞–±–ª–∏—Ü—ã –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏']
                }
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π sheets_manager
            if not self.sheets_manager:
                return {
                    'status': 'no_sheets_manager',
                    'changes': {},
                    'errors': ['GoogleSheetsServiceAccount –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω']
                }
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã
            range_name = f'{sheet_name}!A:R'
            try:
                existing_data = self.sheets_manager.get_sheet_data(spreadsheet_id, range_name)
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ Google Sheets: {e}")
                return {
                    'status': 'sheets_error',
                    'changes': {},
                    'errors': [f'–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∏–∑ Google Sheets: {e}']
                }
            
            if not existing_data or len(existing_data) <= 1:  # –¢–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏–ª–∏ –ø—É—Å—Ç–æ
                return {
                    'status': 'no_previous_data',
                    'changes': {},
                    'errors': []
                }
            
            # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç—Ç–æ–≥–æ URL
            previous_data = None
            for row in reversed(existing_data[1:]):  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏, –∏–¥–µ–º —Å –∫–æ–Ω—Ü–∞
                if len(row) >= 2 and row[1] == url:  # URL –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤–æ –≤—Ç–æ—Ä–æ–º —Å—Ç–æ–ª–±—Ü–µ (B)
                    previous_data = row
                    logger.info(f"–ù–∞–π–¥–µ–Ω—ã –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {url}: {row}")
                    logger.info(f"–î–ª–∏–Ω–∞ —Å—Ç—Ä–æ–∫–∏: {len(row)}")
                    logger.info(f"Title count (—Å—Ç–æ–ª–±–µ—Ü 16): {row[15] if len(row) > 15 else 'N/A'}")
                    logger.info(f"Description count (—Å—Ç–æ–ª–±–µ—Ü 17): {row[16] if len(row) > 16 else 'N/A'}")
                    break
            
            if not previous_data:
                logger.info(f"–ü—Ä–µ–¥—ã–¥—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {url} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ - —ç—Ç–æ –ø–µ—Ä–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞")
                return {
                    'status': 'no_previous_data',
                    'changes': {},
                    'errors': []
                }

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            # –°—Ç—Ä—É–∫—Ç—É—Ä–∞: [–î–∞—Ç–∞, URL, –°—Ç–∞—Ç—É—Å, H1_–Ω–µ–ø—É—Å—Ç—ã–µ, H2_–Ω–µ–ø—É—Å—Ç—ã–µ, ..., H1_–≤—Å–µ–≥–æ, H2_–≤—Å–µ–≥–æ, ...]
            try:
                changes = {}

                # –ù–µ–ø—É—Å—Ç—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ (—Å—Ç–æ–ª–±—Ü—ã 3-8)
                for i in range(1, 7):
                    prev_value = int(previous_data[2 + i]) if len(previous_data) > 2 + i else 0
                    current_value = current_headings.get(f'h{i}_non_empty', 0)

                    # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–Ω–∏—Ü—É
                    diff = current_value - prev_value
                    if diff != 0:
                        changes[f'h{i}_non_empty'] = {'difference': diff, 'previous': prev_value,
                                                      'current': current_value}

                # –û–±—â–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ (—Å—Ç–æ–ª–±—Ü—ã 9-14)
                for i in range(1, 7):
                    prev_value = int(previous_data[8 + i]) if len(previous_data) > 8 + i else 0
                    current_value = current_headings.get(f'h{i}_total', 0)

                    # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–Ω–∏—Ü—É
                    diff = current_value - prev_value
                    if diff != 0:
                        changes[f'h{i}_total'] = {'difference': diff, 'previous': prev_value, 'current': current_value}

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ title (—Å—Ç–æ–ª–±–µ—Ü 16)
                if len(previous_data) > 15:
                    try:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –Ω–µ –ø—É—Å—Ç—ã–µ –∏ –Ω–µ —è–≤–ª—è—é—Ç—Å—è —Å—Ç—Ä–æ–∫–æ–π —Å –ø—Ä–æ–±–µ–ª–∞–º–∏
                        prev_title_raw = previous_data[15]
                        logger.info(f"Title count (—Å—Ç–æ–ª–±–µ—Ü 16): {prev_title_raw} (—Ç–∏–ø: {type(prev_title_raw)})")
                        
                        if prev_title_raw and str(prev_title_raw).strip():
                            prev_title_count = int(prev_title_raw)
                            logger.info(f"–£—Å–ø–µ—à–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–æ –≤ int: {prev_title_count}")
                        else:
                            prev_title_count = 0
                            logger.info(f"Title count –≤ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π: '{prev_title_raw}'")
                        
                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ç–ª–∞–¥–∫–∞
                        logger.info(f"DEBUG: prev_title_raw='{prev_title_raw}', prev_title_count={prev_title_count}")
                    except (ValueError, TypeError) as e:
                        prev_title_count = 0
                        logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ title count '{previous_data[14]}': {e}")
                    
                    current_title_count = current_headings.get('title_count', 0)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                    logger.info(f"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ title –¥–ª—è {url}: –ø—Ä–µ–¥—ã–¥—É—â–µ–µ={prev_title_count}, —Ç–µ–∫—É—â–µ–µ={current_title_count}")
                    
                    if prev_title_count != current_title_count:
                        changes['title_count'] = {
                            'difference': current_title_count - prev_title_count,
                            'previous': prev_title_count,
                            'current': current_title_count
                        }

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ description (—Å—Ç–æ–ª–±–µ—Ü 17)
                if len(previous_data) > 16:
                    try:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –Ω–µ –ø—É—Å—Ç—ã–µ –∏ –Ω–µ —è–≤–ª—è—é—Ç—Å—è —Å—Ç—Ä–æ–∫–æ–π —Å –ø—Ä–æ–±–µ–ª–∞–º–∏
                        prev_description_raw = previous_data[16]
                        logger.info(f"Description count (—Å—Ç–æ–ª–±–µ—Ü 17): {prev_description_raw} (—Ç–∏–ø: {type(prev_description_raw)})")
                        
                        if prev_description_raw and str(prev_description_raw).strip():
                            prev_description_count = int(prev_description_raw)
                            logger.info(f"–£—Å–ø–µ—à–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–æ –≤ int: {prev_description_count}")
                        else:
                            prev_description_count = 0
                            logger.info(f"Description count –≤ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π: '{prev_description_raw}'")
                        
                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ç–ª–∞–¥–∫–∞
                        logger.info(f"DEBUG: prev_description_raw='{prev_description_raw}', prev_description_count={prev_description_count}")
                    except (ValueError, TypeError) as e:
                        prev_description_count = 0
                        logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ description count '{previous_data[15]}': {e}")
                    
                    current_description_count = current_headings.get('description_count', 0)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                    logger.info(f"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ description –¥–ª—è {url}: –ø—Ä–µ–¥—ã–¥—É—â–µ–µ={prev_description_count}, —Ç–µ–∫—É—â–µ–µ={current_description_count}")
                    
                    if prev_description_count != current_description_count:
                        changes['description_count'] = {
                            'difference': current_description_count - prev_description_count,
                            'previous': prev_description_count,
                            'current': current_description_count
                        }

                if changes:
                    return {
                        'status': 'changes_detected',
                        'changes': changes,
                        'errors': []
                    }
                else:
                    return {
                        'status': 'no_changes',
                        'changes': {},
                        'errors': []
                    }
                    
            except (ValueError, IndexError) as e:
                return {
                    'status': 'parsing_error',
                    'changes': {},
                    'errors': [f'–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {e}']
                }
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏: {e}")
            return {
                'status': 'comparison_error',
                'changes': {},
                'errors': [f'–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è: {e}']
            }


class MultiSiteAnalyzer:
    def __init__(self, sites_config_file: str = 'sites_config.json'):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º—É–ª—å—Ç–∏—Å–∞–π—Ç–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        
        Args:
            sites_config_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–∞–π—Ç–æ–≤
        """
        self.sites_config_file = sites_config_file
        self.config = self.load_sites_config()
        self.sheets_manager = GoogleSheetsServiceAccount()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Telegram –±–æ—Ç–∞
        self.telegram_bot = TelegramBot()
        if self.telegram_bot.bot_token and self.telegram_bot.chat_id:
            logger.info("Telegram –±–æ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        else:
            logger.warning("Telegram –±–æ—Ç –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω (–æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç BOT_TOKEN –∏–ª–∏ CHAT_ID)")
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –∏ sheets_manager
        self.parser = SEOParser(config=self.config, sheets_manager=self.sheets_manager)
        
    def load_sites_config(self) -> Dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–∞–π—Ç–æ–≤"""
        if not os.path.exists(self.sites_config_file):
            raise FileNotFoundError(f"–§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ {self.sites_config_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        try:
            with open(self.sites_config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            logger.info(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–∞–π—Ç–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {self.sites_config_file}")
            return config
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
            raise
    
    def get_site_urls(self, site_key: str = None) -> List[str]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ URL –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        
        Args:
            site_key: –ö–ª—é—á —Å–∞–π—Ç–∞ (–µ—Å–ª–∏ None, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ URL)
            
        Returns:
            –°–ø–∏—Å–æ–∫ URL –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        """
        if site_key:
            if site_key not in self.config['sites']:
                # –î–ª—è —Ç–µ—Å—Ç–æ–≤ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫, –∞ –Ω–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ
                return []
            return self.config['sites'][site_key]['urls']
        else:
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å–µ URL –≤—Å–µ—Ö —Å–∞–π—Ç–æ–≤
            all_urls = []
            for site_key, site_data in self.config['sites'].items():
                all_urls.extend(site_data['urls'])
            return all_urls
    
    def get_site_info(self, url: str) -> Dict:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–∞–π—Ç–µ –ø–æ URL
        
        Args:
            url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            
        Returns:
            –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∞–π—Ç–µ
        """
        for site_key, site_data in self.config['sites'].items():
            if any(url.startswith(site_url) for site_url in site_data['urls']):
                return {
                    'key': site_key,
                    'name': site_data['name'],
                    'base_url': site_data['base_url'],
                    'description': site_data['description']
                }
        return {'key': 'unknown', 'name': '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å–∞–π—Ç', 'base_url': '', 'description': ''}
    
    def run_analysis(self, site_key: str = None, custom_urls: List[str] = None) -> Dict[str, List[Dict]]:
        """
        –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è —Å–∞–π—Ç–æ–≤
        
        Args:
            site_key: –ö–ª—é—á –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∞–π—Ç–∞ (–µ—Å–ª–∏ None, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Å–µ)
            custom_urls: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ URL (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é)
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–æ —Å–∞–π—Ç–∞–º
        """
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º URL –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        if custom_urls:
            urls_to_analyze = custom_urls
            logger.info(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ URL: {len(custom_urls)}")
        elif site_key:
            urls_to_analyze = self.get_site_urls(site_key)
            logger.info(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∞–π—Ç '{site_key}': {len(urls_to_analyze)} URL")
        else:
            urls_to_analyze = self.get_site_urls()
            logger.info(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ —Å–∞–π—Ç—ã: {len(urls_to_analyze)} URL")
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º URL –ø–æ —Å–∞–π—Ç–∞–º
        sites_results = {}
        
        for url in urls_to_analyze:
            site_info = self.get_site_info(url)
            site_key = site_info['key']
            
            if site_key not in sites_results:
                sites_results[site_key] = {
                    'site_info': site_info,
                    'results': []
                }
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
            try:
                result = self.parser.analyze_page(url)
                sites_results[site_key]['results'].append(result)
                logger.info(f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞: {url}")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {url}: {e}")
                sites_results[site_key]['results'].append({
                    'url': url,
                    'timestamp': datetime.now().isoformat(),
                    'status': 'error',
                    'error': str(e)
                })
        
        return sites_results
    
    def print_results(self, sites_results: Dict[str, List[Dict]]):
        """–í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
        print("\n" + "="*100)
        print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ú–£–õ–¨–¢–ò–°–ê–ô–¢–û–í–û–ì–û SEO –ê–ù–ê–õ–ò–ó–ê")
        print("="*100)
        
        total_sites = len(sites_results)
        total_pages = sum(len(site_data['results']) for site_data in sites_results.values())
        successful_pages = 0
        
        for site_key, site_data in sites_results.items():
            site_info = site_data['site_info']
            results = site_data['results']
            
            print(f"\nüåê –°–ê–ô–¢: {site_info['name']} ({site_key})")
            print(f"   –û–ø–∏—Å–∞–Ω–∏–µ: {site_info['description']}")
            print(f"   –ë–∞–∑–æ–≤—ã–π URL: {site_info['base_url']}")
            print(f"   –°—Ç—Ä–∞–Ω–∏—Ü –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {len(results)}")
            print("-" * 80)
            
            site_successful = 0
            
            for i, result in enumerate(results, 1):
                print(f"\n   {i}. {result['url']}")
                print(f"      –°—Ç–∞—Ç—É—Å: {result['status']}")
                
                if result['status'] == 'success':
                    site_successful += 1
                    successful_pages += 1
                    
                    headings = result['headings']
                    print("      üìà –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤:")
                    
                    for j in range(1, 7):
                        tag = f'h{j}'
                        total = headings.get(f'{tag}_total', 0)
                        non_empty = headings.get(f'{tag}_non_empty', 0)
                        
                        if total > 0:
                            print(f"        {tag.upper()}: {non_empty} (–≤—Å–µ–≥–æ: {total})")

                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ Title –∏ Description
                    title_count = headings.get('title_count', 0)
                    title_result = headings.get('title_result', '')
                    description_count = headings.get('description_count', 0)
                    description_result = headings.get('description_result', '')

                    print("      üìù Title –∏ Description:")
                    print(f"        Title: {title_result}")
                    print(f"        Description: {description_result}")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
                    if 'comparison' in result:
                        comparison = result['comparison']
                        print(f"      üîç –°—Ä–∞–≤–Ω–µ–Ω–∏–µ: {comparison['status']}")
                        
                        if comparison.get('errors'):
                            print("      ‚ùå –û—à–∏–±–∫–∏:")
                            for error in comparison['errors']:
                                print(f"        - {error}")
                        
                        if comparison.get('changes'):
                            print("      ‚úÖ –ò–∑–º–µ–Ω–µ–Ω–∏—è:")
                            for change_type, change_data in comparison['changes'].items():
                                print(f"        - {change_type}: +{change_data['difference']}")
                else:
                    print(f"      ‚ùå –û—à–∏–±–∫–∞: {result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
            
            print(f"\n   üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∞–π—Ç–∞: {site_successful}/{len(results)} —É—Å–ø–µ—à–Ω–æ")
        
        print("\n" + "="*100)
        print(f"üìà –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f"   üåê –°–∞–π—Ç–æ–≤: {total_sites}")
        print(f"   üìÑ –°—Ç—Ä–∞–Ω–∏—Ü: {total_pages}")
        print(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ: {successful_pages}")
        print(f"   ‚ùå –û—à–∏–±–æ–∫: {total_pages - successful_pages}")
        print(f"   üìä –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {(successful_pages/total_pages*100):.1f}%" if total_pages > 0 else "   üìä –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: 0%")
        print("="*100)
    
    def save_results_locally(self, sites_results: Dict[str, List[Dict]]):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'multi_site_results_{timestamp}.json'
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(sites_results, f, ensure_ascii=False, indent=2)
            
            logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")
            print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
    
    def upload_to_sheets(self, sites_results: Dict[str, List[Dict]]):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ Google Sheets"""
        try:
            settings = self.config['default_settings']
            spreadsheet_id = settings.get('spreadsheet_id')
            sheet_name = settings.get('sheet_name', '–õ–∏—Å—Ç1')
            service_account_file = settings.get('service_account_file', 'service-account-key.json')
            
            if not spreadsheet_id:
                logger.error("–ù–µ —É–∫–∞–∑–∞–Ω ID —Ç–∞–±–ª–∏—Ü—ã –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
                return
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∞–π–ª Service Account –≤ –º–µ–Ω–µ–¥–∂–µ—Ä–µ
            self.sheets_manager.service_account_file = service_account_file
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ (–±–µ–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–∞–π—Ç–∞—Ö)
            all_results = []
            for site_key, site_data in sites_results.items():
                all_results.extend(site_data['results'])
            
            logger.info(f"–ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ Google Sheets: {spreadsheet_id}")
            
            success = self.sheets_manager.upload_results(
                spreadsheet_id, all_results, sheet_name
            )
            
            if success:
                logger.info("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ Google Sheets")
                print("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ Google Sheets")
            else:
                logger.error("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ Google Sheets")
                print("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ Google Sheets")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ Google Sheets: {e}")
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ Google Sheets: {e}")
    
    def send_telegram_report(self, sites_results: Dict[str, List[Dict]]):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç—á–µ—Ç–∞ –≤ Telegram"""
        try:
            if not self.telegram_bot.bot_token or not self.telegram_bot.chat_id:
                logger.warning("Telegram –±–æ—Ç –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ç–ø—Ä–∞–≤–∫—É –æ—Ç—á–µ—Ç–∞")
                return

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            success = self.telegram_bot.send_statistics(sites_results)
            if success:
                logger.info("–û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ –≤ Telegram")
                print("üì± –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ –≤ Telegram")
            else:
                logger.error("–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ—Å–Ω–æ–≤–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ Telegram")
                print("‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ—Å–Ω–æ–≤–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ Telegram")

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
            changes_success = self.telegram_bot.send_detailed_changes(sites_results)
            if changes_success:
                logger.info("–î–µ—Ç–∞–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –≤ Telegram")
                print("üì± –î–µ—Ç–∞–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –≤ Telegram")
            else:
                logger.info("–î–µ—Ç–∞–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã (–Ω–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π –∏–ª–∏ –æ—à–∏–±–∫–∞)")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram: {e}")
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram: {e}")
    
    def send_telegram_error(self, error_message: str):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–µ –≤ Telegram"""
        try:
            if not self.telegram_bot.bot_token or not self.telegram_bot.chat_id:
                return
            
            self.telegram_bot.send_error_notification(error_message)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–µ –≤ Telegram: {e}")
    
    def list_available_sites(self):
        """–í—ã–≤–æ–¥ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å–∞–π—Ç–æ–≤"""
        print("\nüìã –î–û–°–¢–£–ü–ù–´–ï –°–ê–ô–¢–´:")
        print("="*60)
        
        for site_key, site_data in self.config['sites'].items():
            print(f"\nüåê {site_data['name']} ({site_key})")
            print(f"   –û–ø–∏—Å–∞–Ω–∏–µ: {site_data['description']}")
            print(f"   –ë–∞–∑–æ–≤—ã–π URL: {site_data['base_url']}")
            print(f"   –°—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {len(site_data['urls'])}")
            print("   URL:")
            for url in site_data['urls']:
                print(f"     - {url}")

    def analyze_url(self, url: str) -> dict:
        """–ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–¥–ª—è —Ç–µ—Å—Ç–æ–≤)"""
        result = self.parser.analyze_page(url)
        # –ü—Ä–∏–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫ —Ñ–æ—Ä–º–∞—Ç—É, –æ–∂–∏–¥–∞–µ–º–æ–º—É —Ç–µ—Å—Ç–∞–º–∏
        headings = result.get('headings', {})
        return {
            'url': result.get('url'),
            'status_code': result.get('status_code'),
            'h1_count': headings.get('h1_non_empty', 0),
            'h2_count': headings.get('h2_non_empty', 0),
            'h3_count': headings.get('h3_non_empty', 0),
            'total_headings': headings.get('total_headings', 0),
            'title_count': headings.get('title_count', 0),
            'title_result': headings.get('title_result', ''),
            'description_count': headings.get('description_count', 0),
            'description_result': headings.get('description_result', ''),
            'error': result.get('error'),
        }

    def analyze_site(self, site_key: str) -> list:
        """–ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü —Å–∞–π—Ç–∞ (–¥–ª—è —Ç–µ—Å—Ç–æ–≤)"""
        urls = self.get_site_urls(site_key)
        results = []
        for url in urls:
            results.append(self.analyze_url(url))
        return results

    def save_results(self, results: list, filename: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –≤ —Ñ–∞–π–ª (–¥–ª—è —Ç–µ—Å—Ç–æ–≤)"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)


def load_config(config_file: str) -> Dict[str, Any]:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ —Ñ–∞–π–ª–∞"""
    if not os.path.exists(config_file):
        raise FileNotFoundError(f"–§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ {config_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        return config
    except Exception as e:
        raise Exception(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='–ú—É–ª—å—Ç–∏—Å–∞–π—Ç–æ–≤—ã–π SEO –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä')
    parser.add_argument('--config', '-c', default='sites_config.json', 
                       help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–∞–π—Ç–æ–≤')
    parser.add_argument('--site', '-s', 
                       help='–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Å–∞–π—Ç (piter-online, moskva-online, 101internet)')
    parser.add_argument('--list-sites', action='store_true',
                       help='–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å–∞–π—Ç–æ–≤')
    parser.add_argument('--urls', nargs='+',
                       help='–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ URL –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞')
    parser.add_argument('--no-sheets', action='store_true',
                       help='–ù–µ –∑–∞–≥—Ä—É–∂–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ Google Sheets')
    parser.add_argument('--no-local', action='store_true',
                       help='–ù–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ª–æ–∫–∞–ª—å–Ω–æ')
    parser.add_argument('--no-telegram', action='store_true',
                       help='–ù–µ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –æ—Ç—á–µ—Ç –≤ Telegram')
    parser.add_argument('--no-log', action='store_true',
                       help='–ù–µ –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å –ª–æ–≥–∏ –≤ —Ñ–∞–π–ª')
    
    args = parser.parse_args()
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    if args.no_log:
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[logging.StreamHandler()]
        )
    else:
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('multi_site_analyzer.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
    
    logger = logging.getLogger(__name__)
    
    try:
        # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
        analyzer = MultiSiteAnalyzer(args.config)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å–∞–π—Ç–æ–≤
        if args.list_sites:
            analyzer.list_available_sites()
            return
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
        results = analyzer.run_analysis(
            site_key=args.site,
            custom_urls=args.urls
        )
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        analyzer.print_results(results)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ª–æ–∫–∞–ª—å–Ω–æ
        if not args.no_local:
            analyzer.save_results_locally(results)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ Google Sheets
        if not args.no_sheets:
            analyzer.upload_to_sheets(results)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç—á–µ—Ç –≤ Telegram
        if not args.no_telegram:
            analyzer.send_telegram_report(results)
        
        print(f"\nüéâ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
            
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è –ê–Ω–∞–ª–∏–∑ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        analyzer.send_telegram_error("–ê–Ω–∞–ª–∏–∑ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        analyzer.send_telegram_error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
